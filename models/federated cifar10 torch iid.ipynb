{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM6BijapJp0O682/nJ3Fraa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4eebda652eb34441b9e29bc4c1a83735":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aab130c5be6c40f8b891b7834d5ca1c5","IPY_MODEL_ba252a294fbe448da2005ad75798e214","IPY_MODEL_5cec4a60bd19449396a5683e97512d1a"],"layout":"IPY_MODEL_af43ef1bac6e4a70a091b649f224b612"}},"aab130c5be6c40f8b891b7834d5ca1c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99e13733e3d54ef08ae874b67fe35e3f","placeholder":"​","style":"IPY_MODEL_8069578ce33a4523a6652481c4162b78","value":"100%"}},"ba252a294fbe448da2005ad75798e214":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb28a9e1eb0542d4b64bc74a246e248a","max":170498071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ec926b7a5b04226b505fd7be60ffd73","value":170498071}},"5cec4a60bd19449396a5683e97512d1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b0cbe19909c43818c362ad802cdf402","placeholder":"​","style":"IPY_MODEL_b8942d4690c44a3ba6f3cacede599cce","value":" 170498071/170498071 [00:13&lt;00:00, 13715938.54it/s]"}},"af43ef1bac6e4a70a091b649f224b612":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99e13733e3d54ef08ae874b67fe35e3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8069578ce33a4523a6652481c4162b78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb28a9e1eb0542d4b64bc74a246e248a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ec926b7a5b04226b505fd7be60ffd73":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2b0cbe19909c43818c362ad802cdf402":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8942d4690c44a3ba6f3cacede599cce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"n_5Wxx-bBFXy"},"outputs":[],"source":["###############################\n","##### importing libraries #####\n","###############################\n","\n","import os\n","import random\n","from tqdm import tqdm\n","import numpy as np\n","import torch, torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data.dataset import Dataset   \n","torch.backends.cudnn.benchmark=True"]},{"cell_type":"code","source":["##### Hyperparameters for federated learning #########\n","num_clients = 20\n","num_selected = 6\n","num_rounds = 150\n","epochs = 5\n","batch_size = 32"],"metadata":{"id":"t9L6Q0DmJUk7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#############################################################\n","##### Creating desired data distribution among clients  #####\n","#############################################################\n","\n","# Image augmentation \n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","# Loading CIFAR10 using torchvision.datasets\n","traindata = datasets.CIFAR10('./data', train=True, download=True,\n","                       transform= transform_train)\n","\n","# Dividing the training data into num_clients, with each client having equal number of images\n","traindata_split = torch.utils.data.random_split(traindata, [int(traindata.data.shape[0] / num_clients) for _ in range(num_clients)])\n","\n","# Creating a pytorch loader for a Deep Learning model\n","train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in traindata_split]\n","\n","# Normalizing the test images\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","# Loading the test iamges and thus converting them into a test_loader\n","test_loader = torch.utils.data.DataLoader(\n","        datasets.CIFAR10('./data', train=False, transform=transform_test)\n","        ), batch_size=batch_size, shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["4eebda652eb34441b9e29bc4c1a83735","aab130c5be6c40f8b891b7834d5ca1c5","ba252a294fbe448da2005ad75798e214","5cec4a60bd19449396a5683e97512d1a","af43ef1bac6e4a70a091b649f224b612","99e13733e3d54ef08ae874b67fe35e3f","8069578ce33a4523a6652481c4162b78","bb28a9e1eb0542d4b64bc74a246e248a","8ec926b7a5b04226b505fd7be60ffd73","2b0cbe19909c43818c362ad802cdf402","b8942d4690c44a3ba6f3cacede599cce"]},"id":"q4_PuQPTI6ZD","executionInfo":{"status":"ok","timestamp":1665888170918,"user_tz":240,"elapsed":19206,"user":{"displayName":"Md Rafi Rashid","userId":"07573253165411180386"}},"outputId":"6eb750e4-0e32-4dfb-9c48-a843b4f18043"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eebda652eb34441b9e29bc4c1a83735"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n"]}]},{"cell_type":"code","source":["#################################\n","##### Neural Network model #####\n","#################################\n","\n","cfg = {\n","    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n","    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n","}\n","\n","class VGG(nn.Module):\n","    def __init__(self, vgg_name):\n","        super(VGG, self).__init__()\n","        self.features = self._make_layers(cfg[vgg_name])\n","        self.classifier = nn.Sequential(\n","            nn.Linear(512, 512),\n","            nn.ReLU(True),\n","            nn.Linear(512, 512),\n","            nn.ReLU(True),\n","            nn.Linear(512, 10)\n","        )\n","\n","    def forward(self, x):\n","        out = self.features(x)\n","        out = out.view(out.size(0), -1)\n","        out = self.classifier(out)\n","        output = F.log_softmax(out, dim=1)\n","        return output\n","\n","    def _make_layers(self, cfg):\n","        layers = []\n","        in_channels = 3\n","        for x in cfg:\n","            if x == 'M':\n","                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","            else:\n","                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n","                           nn.BatchNorm2d(x),\n","                           nn.ReLU(inplace=True)]\n","                in_channels = x\n","        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n","        return nn.Sequential(*layers)"],"metadata":{"id":"uf1luPbdeLIi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def client_update(client_model, optimizer, train_loader, epoch=5):\n","    \"\"\"\n","    This function updates/trains client model on client data\n","    \"\"\"\n","    model.train()\n","    for e in range(epoch):\n","        for batch_idx, (data, target) in enumerate(train_loader):\n","            data, target = data.cuda(), target.cuda()\n","            optimizer.zero_grad()\n","            output = client_model(data)\n","            loss = F.nll_loss(output, target)\n","            loss.backward()\n","            optimizer.step()\n","    return loss.item()"],"metadata":{"id":"UkQMTwU0f1xs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def server_aggregate(global_model, client_models):\n","    \"\"\"\n","    This function has aggregation method 'mean'\n","    \"\"\"\n","    ### This will take simple mean of the weights of models ###\n","    global_dict = global_model.state_dict()\n","    for k in global_dict.keys():\n","        global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() for i in range(len(client_models))], 0).mean(0)\n","    global_model.load_state_dict(global_dict)\n","    for model in client_models:\n","        model.load_state_dict(global_model.state_dict())"],"metadata":{"id":"_DknM_9Ik8HB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(global_model, test_loader):\n","    \"\"\"This function test the global model on test data and returns test loss and test accuracy \"\"\"\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.cuda(), target.cuda()\n","            output = global_model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    acc = correct / len(test_loader.dataset)\n","\n","    return test_loss, acc"],"metadata":{"id":"se2eOfY3nOik"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["############################################\n","#### Initializing models and optimizer  ####\n","############################################\n","\n","#### global model ##########\n","global_model =  VGG('VGG19').cuda()\n","\n","############## client models ##############\n","client_models = [ VGG('VGG19').cuda() for _ in range(num_selected)]\n","for model in client_models:\n","    model.load_state_dict(global_model.state_dict()) ### initial synchronizing with global model \n","\n","############### optimizers ################\n","opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]"],"metadata":{"id":"TmDfwJ6mqaYf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###### List containing info about learning #########\n","losses_train = []\n","losses_test = []\n","acc_train = []\n","acc_test = []\n","# Runnining FL\n","\n","for r in range(num_rounds):\n","    # select random clients\n","    client_idx = np.random.permutation(num_clients)[:num_selected]\n","    # client update\n","    loss = 0\n","    for i in tqdm(range(num_selected)):\n","        loss += client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch=epochs)\n","    \n","    losses_train.append(loss)\n","    # server aggregate\n","    server_aggregate(global_model, client_models)\n","    \n","    test_loss, acc = test(global_model, test_loader)\n","    losses_test.append(test_loss)\n","    acc_test.append(acc)\n","    print('%d-th round' % r)\n","    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))"],"metadata":{"id":"VyFztfjYq0by"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ps3XDlFisqLS"},"execution_count":null,"outputs":[]}]}